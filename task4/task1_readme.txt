Обучение и использование модели распознавания рукописных цифр (MNIST)

Этот код представляет собой реализацию модели нейронной сети с использованием библиотеки TensorFlow и Keras для распознавания рукописных цифр с помощью набора данных MNIST. Набор данных MNIST содержит изображения цифр от 0 до 9, каждое размером 28x28 пикселей.

Модель нейронной сети состоит из трех слоев:

Входной слой (Flatten): Преобразует двумерные изображения 28x28 в одномерный массив 784 элементов.
Первый скрытый слой (Dense): Состоит из 128 нейронов с функцией активации ReLU (Rectified Linear Unit).
Второй скрытый слой (Dense): Состоит из еще 128 нейронов с функцией активации ReLU.
Выходной слой (Dense): Состоит из 10 нейронов с функцией активации softmax для классификации на 10 классов (цифры от 0 до 9).
Для улучшения обобщающей способности модели и предотвращения переобучения применяются слои Dropout с коэффициентом 0.2.

Установка и настройка:
Установите необходимые библиотеки: tensorflow, matplotlib, numpy, pandas, sklearn.

Обучение модели:
Загрузка данных: Для обучения модели используется набор данных MNIST, который автоматически загружается из библиотеки TensorFlow с помощью функции mnist.load_data(). Данные разделяются на обучающий набор (tr_images, tr_labels) и тестовый набор (ts_images, ts_labels).

Предобработка данных: Изображения нормализуются, чтобы значения пикселей находились в диапазоне от 0 до 1, делением каждого значения на 255.

Создание модели: Модель создается с помощью tf.keras.models.Sequential, который позволяет добавлять слои последовательно.

Компиляция модели: Модель компилируется с оптимизатором "adam", функцией потерь "sparse_categorical_crossentropy" (так как метки классов являются целыми числами) и метрикой "accuracy" для оценки производительности.

Обучение модели: Модель обучается на обучающих данных (tr_images, tr_labels) с использованием функции model.fit. Также используется валидационный набор данных (val_images, val_labels) для оценки производительности модели на каждой эпохе.

Оценка модели: После обучения модели оценивается ее производительность на тестовом наборе данных (ts_images, ts_labels) с помощью функции model.evaluate.

Визуализация результатов: Используются библиотеки matplotlib и pandas, чтобы визуализировать историю обучения, а также построить матрицу ошибок (Confusion Matrix) для оценки производительности модели.

Параметры модели
epochs: Количество эпох обучения модели. Значение 10 было выбрано, чтобы дать модели достаточно эпох для сходимости и обучения на данных.

batch_size: Размер пакета для обучения модели. В данном коде размер пакета не задается явно, и по умолчанию используется значение 32.

Dropout: Коэффициент Dropout установлен на 0.2. Это помогает предотвратить переобучение, отключая случайные нейроны на каждой эпохе обучения.

Визуализация результатов
Графики истории обучения позволяют оценить, как изменяется производительность модели в зависимости от количества эпох. График потерь (Loss) показывает, как уменьшается ошибка модели с увеличением количества эпох, а график точности (Accuracy) показывает, как увеличивается точность модели на обучающем и валидационном наборах данных.

Матрица ошибок (Confusion Matrix) предоставляет детальную информацию о том, как модель классифицирует каждый класс. Она отображает количество правильно и неправильно классифицированных примеров для каждого класса, что позволяет оценить точность и перекосы в классификации.

Сохранение модели
Обученная модель сохраняется в файл с расширением .h5 с помощью функции model.save(). После сохранения, вы можете загрузить модель и использовать ее для предсказания новых данных без необходимости повторного обучения.
